# ğŸ§© Desafio PrÃ¡tico

Esta pÃ¡gina contÃ©m as instruÃ§Ãµes necessÃ¡rias para utilizar o projeto, que realiza o deploy de um modelo de previsÃ£o de demanda de vendas. A implementaÃ§Ã£o foi desenvolvida utilizando o conjunto de ferramentas disponÃ­veis na Google Cloud Platform (GCP).

### 1. Requisitos ğŸ“‹

âœ… PermissÃµes na GCP: Ã‰ necessÃ¡rio ter perfil de administrador na conta da Google Cloud Platform (GCP) da sua empresa.

ğŸ› ï¸ Ferramentas utilizadas:

- [Python](https://www.python.org/) para desenvolvimento do modelo.
- [Terraform](https://www.terraform.io/) gerenciamento de infraestrutura.
- [Poetry](https://python-poetry.org/) gerenciamento de dependÃªncias do projeto.
- [gcloud CLI](https://cloud.google.com/) ferramenta de linha de comando da Google Cloud. 
- [Git](https://git-scm.com/) ferramenta para controle de controle de versÃ£o de cÃ³digo.

ğŸ’» Ambiente de desenvolvimento: O projeto foi desenvolvido e testado em uma mÃ¡quina com [Linux Ubuntu](https://ubuntu.com/) *24.04*.

### 2. Google Cloud

Efetue o login na Google Cloud com o comando:

```bash
gcloud auth login
```

Ã‰ preciso abilitar as APIs na GCP. Para isso, use o comando:

```bash
gcloud services enable \
    composer.googleapis.com \
    compute.googleapis.com \
    aiplatform.googleapis.com \
    storage.googleapis.com \
    pubsub.googleapis.com \
    cloudfunctions.googleapis.com \
    monitoring.googleapis.com \
    logging.googleapis.com
```

Adicione permissÃ£o para seu o usuario poder executar o *Composer*, verifique no *IAM* a sua conta ou crie uma
de serviÃ§o:

```bash
gcloud projects add-iam-policy-binding SEU-PROJECTO-NA-GCP \
  --member="serviceAccount:service-XXX11@cloudcomposer-accounts.iam.gserviceaccount.com" \
  --role="roles/composer.ServiceAgentV2Ext"
```

### 3. Projeto ğŸš€

Siga os passos abaixo para configurar e executar o projeto na sua estaÃ§Ã£o de trabalho:

1. **Baixe o projeto**:

FaÃ§a o download do projeto para o seu ambiente local.

2. **Navegue atÃ© o diretÃ³rio do projeto e configure o ambiente**

Execute os seguintes comandos no terminal: 

```bash
cd ml-sales-model && poetry shell && poetry update
```

- cd ml-sales-model: Acessa o diretÃ³rio do projeto.
- poetry shell: Ativa o ambiente virtual do Poetry.
- poetry update: Atualiza / instala as dependÃªncias do projeto.

3. **Treine e teste o modelo localmente**

Para treinar o modelo de teste, execute:

```bash
python3.11 experiments/model.py
```

- Esse comando irÃ¡ treinar o modelo e salvar o arquivo pickle na pasta **data/**.

4. **Sobre o dataset**

Foi utilizado um dataset de testes exclusivamente para validar o fluxo de criaÃ§Ã£o do modelo. Ele nÃ£o representa dados **reais**, mas sim um exemplo para garantir que o pipeline funcione corretamente.

#### 3.1 Infraestrutura na GCP com Terraform ğŸŒ

Agora, Ã© necessÃ¡rio criar a infraestrutura na Google Cloud Platform (GCP) utilizando o Terraform. Siga os passos abaixo:

1. **Ajuste as variÃ¡veis do Terraform**

- Edite o arquivo *(terraform/terraform.tfvars*) para configurar as variÃ¡veis de acordo com o seu ambiente na GCP.
- Certifique-se de ajustar parÃ¢metros como:
  - Project ID: O ID do seu projeto na GCP.
  - Region/Zone: A regiÃ£o e zona onde os recursos serÃ£o provisionados.
  - Credenciais da Conta: A conta de serviÃ§o que o Terraform utilizarÃ¡ para autenticaÃ§Ã£o.

Exemplo de variÃ¡veis:

```hcl
GOOGLE_CREDENTIALS_PATH = "~/.config/gcloud/service@xxx.com.json"
GOOGLE_PROJECT_ID       = "meu-projeto-na-gcp"
GOOGLE_REGION           = "us-west-1"
```

Depois de ajustar as variaveis:

```hcl
terraform/terraform.tfvars 
```

2. **Terraform**

Execute o comando abaixo para inicializar o Terraform e baixar os providers necessÃ¡rios:

```bash
cd terraform && terraform init
```

3. **Valide a configuraÃ§Ã£o**

Verifique se o arquivo de configuraÃ§Ã£o estÃ¡ correto com o comando:

```bash
terraform validate
```

4. **Planeje a infraestrutura**

Use o comando terraform plan para visualizar as mudanÃ§as que serÃ£o aplicadas:

```bash
terraform plan
```

5. **Aplique a infraestrutura**

Para criar os recursos na GCP, execute:

```bash
terraform apply
```

Confirme a aÃ§Ã£o digitando **yes** quando solicitado.

**ObservaÃ§Ãµes importantes ğŸš¨**

- Confirme se todos os recursos foram criados na GPC.
- Certifique-se de que a conta de serviÃ§o utilizada pelo Terraform tenha permissÃµes suficientes para criar e gerenciar recursos na GCP.
- Mantenha o arquivo (*terraform.tfstate*) seguro, pois ele contÃ©m o estado atual da sua infraestrutura.

#### 3.2. Pipeline de Treino e Deploy ğŸš€ğŸ“Š

Agora, Ã© necessÃ¡rio ajustar as variÃ¡veis no script de treino do modelo e registrÃ¡-lo no Vertex AI. ğŸ› ï¸ğŸ¤–

1. **Terminal**

Primeiro, defina a variÃ¡vel de ambiente no terminal:

```bash
export GOOGLE_APPLICATION_CREDENTIALS="caminho/para/sua/chave.json"
```

2. **Treino**

Edite o script Python *(pipelines/train_model.py)* ğŸ–‹ï¸ğŸ e ajuste as variÃ¡veis: ğŸ”§ğŸ“

```hcl
project_id = ""
region = ""
bucket_name = ""
```

3. **Bucket**

Copie os arquivos para o bucket da GCP:

```bash
gsutil cp data/sales_dataset.csv gs://mlops-models15/
gsutil cp data/sales_forecast_model.pkl gs://mlops-models15/models
```

4. **Teste**

VocÃª pode nesse momento executar o script:

```bash
python3.11 pipelines/train_model.py
```

Verifique no Vertex AI a pipeline de treino sendo executada.

#### 3.3. Monitoramento

Agora precisamos garantir o monitoramento do modelo.

1. **VariÃ¡veis**

Ajuste as variÃ¡veis no script de deploy *(pipelines/deploy_model.py)*: ğŸ”§ğŸ“

```hcl
project_id = ""
region = "us-west1"
```

2. **Cloud Function**

Crie uma Cloud Function para monitorar o deploy:

```bash
gcloud functions deploy deploy_model \
  --runtime python311 \
  --trigger-event google.storage.object.finalize \
  --trigger-resource seu_projeto_gcp-ml-bucket \
  --entry-point deploy_model
```

3. **Logs e Monitoramento**

ConfiguraÃ§Ã£o de Logging:

```bash
gcloud logging sinks create ml_logs \
  storage.googleapis.com/seu_projeto_gcp-ml-bucket
```

4. **Criando Alerta no Cloud Monitoring**

Criamos um alerta que notifica via Pub/Sub caso a latÃªncia da inferÃªncia ultrapasse *500ms*.

```bash
gcloud pubsub topics create ml_alerts
```

Agora crie o alerta:

```bash
gcloud monitoring policies create \
  --notification-channels=ml_alerts \
  --display-name="Alerta de LatÃªncia no Modelo de Vendas" \
  --condition-threshold-value=500 \
  --condition-threshold-comparison=COMPARISON_GT \
  --condition-threshold-aggregations=alignment_period=60s,per_series_aligner=ALIGN_PERCENTILE_99 \
  --condition-threshold-filter='metric.type="serving_latency"' \
  --duration=60s
```

#### 4. ConclusÃ£o

Resumo do que foi feito:

- âœ… Infraestrutura como CÃ³digo (IaC)

Terraform provisiona Cloud Storage, Cloud Composer (Airflow) e Vertex AI Training Job.

- âœ… Pipeline de Treinamento e Deploy

Script Python para treinar o modelo, salvar no Cloud Storage e registrar no Vertex AI.

- âœ… Monitoramento e Logging

Voltar ao [README](./README.md) ğŸ‘ˆ inicial.
Cloud Logging armazena logs do treinamento e inferÃªncia. 
Cloud Monitoring cria um alerta via Pub/Sub caso a latÃªncia ultrapasse 500ms.

Com isso, temos um pipeline completo para treino, deplo e monitoramento do modelo na GCP. ğŸš€
