# ğŸ§© Conceitos e Arquitetura

Nessa pÃ¡gina contÃ©m as respostas das perguntas teÃ³ricas elaboradas pelo cliente.

### 1. ğŸ—ï¸ Infraestrutura e OrquestraÃ§Ã£o

**Vertex AI Pipelines** e **Kubeflow Pipelines** sÃ£o duas soluÃ§Ãµes para orquestraÃ§Ã£o fluxos de **Machine Learning**. Ambos permitem criar, gerenciar e monitorar pipelines de ML, mas tÃªm diferenÃ§as em termos de integraÃ§Ã£o, facilidade de uso e casos de uso ideais. Abaixo as principais diferenÃ§as:

- Vertex AI Pipelines Ã© um serviÃ§o totalmente gerenciado do Google Cloud, parte da plataforma Vertex AI, que simplifica a criaÃ§Ã£o e execuÃ§Ã£o de pipelines (esteiras) de ML.
- Ele Ã© baseado no Kubeflow Pipelines, mas abstrai a complexidade.
- Kubeflow Pipelines Ã© uma plataforma de cÃ³digo aberto para orquestraÃ§Ã£o de workflows de ML, projetada para rodar em Kubernetes.
- Ele oferece mais flexibilidade e controle, mas requer configuraÃ§Ã£o e gerenciamento de infraestrutura.

ğŸ§­ Vantagens do **Vertex AI Pipelines**:

- Uma soluÃ§Ã£o pronta para uso com mÃ­nimo esforÃ§o de configuraÃ§Ã£o.
- Focado em produtividade, vocÃª nÃ£o quer gerenciar infraestruturas complexas.
- A empresa jÃ¡ usa outros serviÃ§os do Vertex AI e deseja integraÃ§Ã£o.

ğŸ§­ Vantagens do **Kubeflow Pipelines**:

- A empresa precisa de controle total sobre a infraestrutura e pipelines.
- A empresa tem expertise em Kubernetes e deseja personalizar o ambiente do seu jeito.
- A empresa precisa de portabilidade entre diferentes nuvens (multi-cloud) ou ambientes on-premises, exemplo (Cloudera).

#### 1.1 ğŸ”§ Infraestrutura de ML

Para essa pergunta, tem que entender detalhes do cliente os tipos de modelos que serÃ£o implemendados. Mas, pensando em uma estrutura enxuta e escalÃ¡vel usando GCP, podemos pensar em uma arquitetura simples e objetiva:

##### ğŸ•¹ï¸ Requisitos da Arquitetura

Modelos **Batch** ğŸ“¦:

- Processamento periÃ³dico de mÃ©dio volumes de dados.

*Exemplos*: previsÃµes diÃ¡rias, geraÃ§Ã£o de relatÃ³rios, treinamento de modelos.

Modelos **Fast** âš¡:

- Respostas em tempo real ou near real-time.

*Exemplos*: previsÃµes online, modelo de NLP, detecÃ§Ã£o facial, etc...

##### ğŸ¯ Arquitetura Proposta

Steps:

1. Coleta de Dados ğŸ“¶

- Cloud Pub/Sub: Para ingestÃ£o de dados em tempo real (*fast*).
- Cloud Storage: Para armazenamento de dados brutos em (*batch*).
  
*Exemplos*: APIs para previsÃµes sob demanda, detecÃ§Ã£o de anomalias em tempo real.

2. Processamento de Dados ğŸ§®

- Dataflow: Para processamento de dados em *batch* ou *streaming*.
- BigQuery: Para armazenar dados processados e estruturados (tabelas).

3. Treinamento de Modelos ğŸ¤–

- Vertex AI Training: Para treinar modelos de forma gerenciada.
- Cloud Storage: Para armazenar modelos treinados e backups dos mesmos.

3. Armazenamento / Controle de Modelos ğŸ—‚ï¸

- Vertex AI Model Registry: Para versionamento e gerenciamento de modelos.
- Cloud Storage: Para armazenar arquivos de modelos (h5, pickle, joblib, etc...).

5. Deploy ğŸš€
   
- Vertex AI Endpoints: Para servir modelos em tempo real (*fast*).
- Cloud Functions ou Cloud Run: Para execuÃ§Ã£o de modelos batch sob demanda ou em horÃ¡rios agendados.

Para caso de modelo batch disponibilizaÃ§Ã£o das inferÃªncias em uma tabela no BigQuery.

6. Monitoramento e Logging ğŸ”

- Cloud Logging: Coleta e armazenamento de logs em grande escala.
- Vertex AI Model Monitoring: Escalabilidade automÃ¡tica para monitorar a qualidade dos modelos em produÃ§Ã£o (drift + mÃ©tricas).

7. Diagrama ğŸ“Š

Fluxo bÃ¡sico para modelos **Fast** e **Batch**

```mermaid
flowchart TD
    A[Coleta de Dados] --> B[Cloud Pub/Sub]
    A --> C[Cloud Storage]
    B --> D[Dataflow Streaming]
    C --> E[Dataflow Batch]
    D --> F[BigQuery]
    E --> G[Vertex AI Training]
    F --> H[Vertex AI Endpoints]
    G --> I[Cloud Storage Modelos]
    H --> J[Cloud Logging & Monitoring]
    I --> K[Cloud Scheduler + Cloud Run]
```

### 2. ğŸ•¸ï¸ CI/CD para Machine Learning

A implementaÃ§Ã£o de um pipeline de *CI/CD* simples e eficiente, podemos seguir as seguintes steps e ferramentas detalhadas
a seguir.

#### 1.2 ğŸ”§ Estrutura dos Projetos

Os projetos de ML devem seguir um **template** que deve ser utilizada por todos os *cientistas de dados* do time. Usando o GitHub
como exemplo, podemos criar um template padrÃ£o dos projetos usando o cookie cutter. Sendo assim todos os projetos seguem as templates
padrÃ£o da empresa.

Estrutura do Projeto:

```txt
project-ml/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ queries/
â”œâ”€â”€ scripts/
â”œâ”€â”€ src/
â”œâ”€â”€ terraform/
â”œâ”€â”€ cloudbuild.yaml
â””â”€â”€ requirements.txt
```

#### 1.3 ğŸ‘¨â€ğŸ’» Terraform

Usando o *Terraform* para definir a infraestrutura necessÃ¡ria, como buckets, serviÃ§os do Vertex AI, e outros recursos GCP.

*Exemplo*:

```terraform
provider "google" {
  project = "projeto-gcp-modelos"
  region  = "southamerica-east1-a"
}

resource "google_storage_bucket" "model_bucket" {
  name     = "bucket-modelos"
  location = "BR"
}

resource "google_vertex_ai_dataset" "dataset" {
  display_name = "meu-dataset"
  region       = "southamerica-east1-a"
}
```

#### 1.4 ğŸ­ Cloud Build

ConfiguraÃ§Ã£o de exemplo do *Cloud Build*:

```yaml
# Passo 1: Instalar dependÃªncias
- name: 'python:3.12'
  id: 'Instalar DependÃªncias'
  entrypoint: 'pip'
  args: ['install', '-r', 'requirements.txt']

# Passo 2: Treinar o modelo
- name: 'python:3.12'
  id: 'Treinar Modelo'
  entrypoint: 'python'
  args: ['scripts/train.py']

# Passo 3: Validar o modelo
- name: 'python:3.12'
  id: 'Validar Modelo'
  entrypoint: 'python'
  args: ['scripts/validate.py']

# Passo 4: Deplot do modelo no Vertex AI
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'Implantar Modelo'
  args: ['ai-platform', 'models', 'create', 'meu-modelo', '--region=southamerica-east1-a']
```

#### 1.5 ğŸ² IntegraÃ§Ã£o Vertex AI

- Usando o Vertex AI para treinar o modelo. Podemos enviar os jobs de treinamento diretamente a partir do Cloud Build.
- Registro do Modelo: Usando o Vertex AI Model Registry para ter o controle e gerenciamento do modelo.
- Deploy do Modelo: ApÃ³s o treinamento, implantamos o modelo no Vertex AI.

#### 1.6 â° Triggers

- Podemos usar Trigger de Push: No Cloud Build executar a pipeline automaticamente quando houver um push para o branch (main) do repositÃ³rio no GitHub.
- Pull Request: Podemos configurar triggers para executar testes automatizados quando um (*pull request*) for aberto.

#### 1.7 ğŸ˜ Boas prÃ¡ticas

Ã‰ essencial manter uma documentaÃ§Ã£o detalhada dos modelos, incluindo *runbooks* para orientar as operaÃ§Ãµes, uma estratÃ©gia de *rollback* bem definida e, no caso de modelos *batch*, os horÃ¡rios programados para a execuÃ§Ã£o das inferÃªncias, entre outros aspectos relevantes.

Ã‰ fundamental implementar um monitoramento contÃ­nuo dos modelos, utilizando dashboards em ferramentas como Cloud Monitoring, Looker ou outras plataformas de visualizaÃ§Ã£o de dados, para acompanhar mÃ©tricas de desempenho e identificar possÃ­veis drifts. AlÃ©m disso, Ã© importante configurar alertas automatizados que notifiquem o responsÃ¡vel pelo modelo em caso de problemas, garantindo uma resposta rÃ¡pida e eficiente.

Nesse ponto, Ã© importante salientar que, dependendo do problema que o modelo busca resolver, Ã© possÃ­vel implementar uma pipeline de re-treinamento automÃ¡tico, que serÃ¡ acionada sempre que uma mÃ©trica especÃ­fica atingir um nÃ­vel de degradaÃ§Ã£o prÃ©-definido. Essa abordagem ajuda a manter a eficÃ¡cia do modelo ao longo do tempo, adaptando-se Ã s mudanÃ§as nos dados e no ambiente.

Ã‰ imprescindÃ­vel realizar testes e validaÃ§Ãµes *robustas*, usar Feature Store, scripts automatizados que assegurem a execuÃ§Ã£o de todos os testes necessÃ¡rios antes do deploy do modelo. Essa prÃ¡tica garante a confiabilidade e a qualidade do modelo, identificando possÃ­veis falhas ou inconsistÃªncias que possam impactar seu desempenho em produÃ§Ã£o.

*Exemplos*:

 - Testes unitÃ¡rios.
 - Uso de Feature Stores.
 - Volumetria dos dados.

#### 1.8 ğŸ“Š Diagrama

Fluxo da pipeline

```mermaid
flowchart TD
    A[Push para o RepositÃ³rio] --> B[Trigger do Cloud Build]
    B --> C[InstalaÃ§Ã£o de DependÃªncias]
    C --> D[Treinamento do Modelo]
    D --> E[ValidaÃ§Ã£o do Modelo]
    E --> F[Implantacao do Modelo]
    F --> G[Monitoramento]
```

#### 1.9 â³ Gerenciamento com Vertex AI Model Registry

Para fazer o versionamento dos modelos, usamos o Vertex AI Model Registry. Ele facilita o controle de diferentes versÃµes de um modelo, garantindo rastreabilidade e a capacidade de reverter para versÃµes anteriores, caso necessÃ¡rio.

**ğŸ¢ Steps para Registrar um Modelo**:

Lembrando as steps abaixo estaram dentro de uma pipeline usando o terraform, mas para facilitar
vamos fazer step by step.

ApÃ³s treinar um modelo, podemos registrÃ¡-lo.

*Exemplo*:

```sh
gcloud ai models upload --region=REGION --display-name=MODEL_NAME --container-image-uri=IMAGE_URI
```

AutomÃ¡ticamente o modelo serÃ¡ registrado com a versÃ£o **v1**. Podemos listar os modelos registrados:

```sh
gcloud ai versions list --model=MODEL_NAME --region=REGION
```

Agora, suponhamos que esse modelo sofreu um re-treino. Subimos a nova versÃ£o do modelo re-treinado:

```sh
gcloud ai models set-default-version --model=MODEL_NAME --region=REGION --version=VERSION_NAME
```

Agora a versÃ£o sera a **v2**. A pipeline rodou alguns testes e verificamos que o modelo anterior ainda
era melhor. EntÃ£o Ã© necessÃ¡rio fazer o rollback para v1.

```sh
gcloud ai models set-default-version --model=MODEL_NAME --region=REGION --version=v1
```

Pronto ğŸ¤Ÿ! O modelo anterior estara funcionando novamente. Esses sÃ£o os benefÃ­cios do versionamento no Vertex AI Model Registry. 

- ğŸ‘‰ Rastreabilidade: MantÃ©m um histÃ³rico completo de todas as versÃµes do modelo.
- ğŸ‘‰ Facilidade de ReversÃ£o: Permite reverter para versÃµes anteriores rapidamente em caso de problemas.
- ğŸ‘‰ ColaboraÃ§Ã£o: Facilita o trabalho em equipe, permitindo que diferentes versÃµes sejam testadas e comparadas.

### 3. ğŸ” Monitoramento e Observabilidade 

JÃ¡ falamos um pouco acima do monitoramento. Mas vamos detalhar mais.

O drift Ã© uma mÃ©trica de monitoramento, ocorre quando a relaÃ§Ã£o entre as variÃ¡veis de entrada e a variÃ¡vel de saÃ­da muda ao longo do tempo, 
afetando a performance do modelo. 

*Exemplo*:

O modelo foi treinado usando dados do passado para prever o presente e futuro. PorÃ©m esses dados ao longo
do tempo vÃ£o mudando, entÃ£o o drift verifica esse desvio entre as mudanÃ§as nas variavels.

Usando a **GCP**, podemos usar ferramentas como *Vertex AI Model Monitoring* para detectar esse tipo de problema.

- ğŸ‘‰ Ao fazer o deploy do modelo podemos habilitar o monitoramento contÃ­nuo, para rastrear o drift.
- ğŸ‘‰ Podemos definir os (thresholds) para mÃ©tricas, e quando se degradar alertamos via email o time, por exemplo.

Como podemos reagir ao drift:

- ğŸ‘‰ Retreinar o modelo com dados mais recentes.
- ğŸ‘‰ Ajustar os hiperparÃ¢metros do modelo.
- ğŸ‘‰ Investigar se houve mudanÃ§as bruscas nos dados.

AlÃ©m do drift de dados, existe outras mÃ©tricas que sÃ£o importantes acompanhar como *F1-Score*, *AUC-ROC*, *AcurÃ¡cia*, *MAE*, *RMSE*, entre
outras. Em casos de modelos *Fast*, acompanhar a latÃªncias de respostas dos *requests*.

```Nota ğŸ“‘```: Esse processo em alguns casos pode ser complexo, entÃ£o podemos criar uma pipeline de re-treino automÃ¡tica para
treinar o modelo com dados mais recentes ou investigar o problema antes de tentar re-treinar automaticamente. 

Para o ferramental na *GCP* podemos usar para monitoramento:

- ğŸ‘‰ Vertex AI Model Monitoring: Automatiza o monitoramento de mÃ©tricas e alertas.
- ğŸ‘‰ Cloud Monitoring: Configura alertas personalizados para mÃ©tricas especÃ­ficas.
- ğŸ‘‰ BigQuery: Armazena logs e mÃ©tricas para anÃ¡lise histÃ³rica.
- ğŸ‘‰ Dataflow: Processa dados em tempo real para monitoramento contÃ­nuo.
- ğŸ‘‰ Escrever um soluÃ§Ã£o personalizada usando Cloud Run.

### 4. SeguranÃ§a e Compliance ğŸ”

A GCP oferece alguns serviÃ§os e prÃ¡ticas recomendadas para proteger os dados. Algumas sÃ£o padrÃµes nos
serviÃ§os como *AES-256*, *TLS* para garantir que os dados sejam criptografados durante as transferÃªncia entre serviÃ§os.

Ã‰ importante fazer o controle dos acessos via *IAM*. 

*Exemplos*:

- Definir permissÃµes granulares e garantir que apenas usuÃ¡rios e serviÃ§os autorizados tenham acesso aos dados.
- Aplicar o princÃ­pio do menor privilÃ©gio, concedendo apenas as permissÃµes necessÃ¡rias.

CriaÃ§Ã£o de Service Accounts:

- Utilizar contas de serviÃ§o para autenticar aplicaÃ§Ãµes, evitando o uso de credenciais de usuÃ¡rios humanos.

Usar VPC ğŸŒ¥ï¸:

Configurando limites para restringir o acesso a serviÃ§os como BigQuery, Cloud Storage e Vertex AI, evitando vazamentos de dados.

AnonimizaÃ§Ã£o de Dados

*Exemplos*:

- Data Loss Prevention (DLP) API: Identificar e anonimizar informaÃ§Ãµes sensÃ­veis, como CPFs, nÃºmeros de cartÃ£o de crÃ©dito ou endereÃ§os de e-mail.
- PseudonimizaÃ§Ã£o: Substitua identificadores diretos por valores pseudÃ´nimos, mantendo a utilidade dos dados para treinamento sem expor informaÃ§Ãµes sensÃ­veis.

Usar **ambientes seguros** para treino, usando serviÃ§os como:

- Vertex AI: O Vertex AI oferece um ambiente seguro para treinar modelos, com integraÃ§Ã£o nativa ao IAM e criptografia de dados.
- AI Platform Notebooks: Utilizar notebooks gerenciados com controles de acesso e criptografia para desenvolver e testar modelos.

Ativar IPs e VPCs:

Configurar *redes privadas* para garantir que o trÃ¡fego de dados nÃ£o seja exposto Ã  internet pÃºblica.

Usar o Cloud Audit Logs:

- Habilitar logs de auditoria para rastrear todas as aÃ§Ãµes realizadas nos serviÃ§os do GCP, como acessos a dados e operaÃ§Ãµes de treinamento.

Para proteger pipelines de treinamento, usaria as ferramentas e as praticas a seguir: 

**IAM ğŸ”‘**

- Seguindo o princÃ­pio do menor privilÃ©gio possÃ­vel.
- PapÃ©is (Roles) prÃ©-definidos e customizados.
- Grupos de usÃºarios (por exemplo, *data-scientists*, *ml-engineers*, *data-engineers*), em vez de a usuÃ¡rios individuais.

**Service Accounts ğŸ”‘**

Contas de serviÃ§o sÃ£o usadas para autenticar aplicaÃ§Ãµes e serviÃ§os, evitando o uso de credenciais pessoais.

- Contas de ServiÃ§o EspecÃ­ficas: Dedicadas para pipelines de treinamento e inferÃªncia.
- LimitaÃ§Ã£o de Escopo: O escopo das contas de serviÃ§o apenas Ã s permissÃµes necessÃ¡rias para executar suas tarefas.

Outras prÃ¡ticas podem ser adotas como criaÃ§Ã£o de token e expiraÃ§Ã£o dos mesmos. UsuÃ¡rios e chaves especÃ­ficas para o 
CI/CD dos repositÃ³rios de cÃ³digo fonte, usar serviÃ§os como Secret Manager, implementaÃ§Ã£o da auditoria de logs, usando 
Cloud Audit Logs, Cloud Monitoring, Security Command Center, existe uma serie de possibilidades e ferramental disponivel.

