# ðŸ§© Conceitos e Arquitetura

Nessa pÃ¡gina contÃ©m as respostas das perguntas teÃ³ricas elaboradas pelo cliente.

### 1. ðŸ—ï¸ Infraestrutura e OrquestraÃ§Ã£o

**Vertex AI Pipelines** e **Kubeflow Pipelines** sÃ£o duas soluÃ§Ãµes para orquestraÃ§Ã£o fluxos de **machine learning**. Ambos permitem criar, gerenciar e monitorar pipelines de ML, mas tÃªm diferenÃ§as em termos de integraÃ§Ã£o, facilidade de uso e casos de uso ideais. Abaixo as principais diferenÃ§as:

- Vertex AI Pipelines Ã© um serviÃ§o totalmente gerenciado do Google Cloud, parte da plataforma Vertex AI, que simplifica a criaÃ§Ã£o e execuÃ§Ã£o de pipelines de ML.
- Ele Ã© baseado no Kubeflow Pipelines, mas abstrai a complexidade.
- Kubeflow Pipelines Ã© uma plataforma de cÃ³digo aberto para orquestraÃ§Ã£o de workflows de ML, projetada para rodar em Kubernetes.
- Ele oferece mais flexibilidade e controle, mas requer configuraÃ§Ã£o e gerenciamento de infraestrutura.

ðŸ§­ Vantagens do **Vertex AI Pipelines**:

- VocÃª quer uma soluÃ§Ã£o pronta para uso com mÃ­nimo esforÃ§o de configuraÃ§Ã£o.
- VocÃª estÃ¡ focado em produtividade e nÃ£o quer gerenciar infraestruturas complexas.
- VocÃª jÃ¡ usa outros serviÃ§os do Vertex AI e deseja integraÃ§Ã£o.

ðŸ§­ Vantagens do **Kubeflow Pipelines**:

- VocÃª precisa de controle total sobre a infraestrutura e pipelines.
- VocÃª tem expertise em Kubernetes e deseja personalizar o ambiente do seu jeito.
- VocÃª precisa de portabilidade entre diferentes nuvens ou ambientes on-premises.

#### 1.1 ðŸ”§ Infraestrutura de ML

Tem que entender detalhes do cliente os tipos de modelos que serÃ£o implemendados. Mas, pensando em uma estrutura enxuta e escalavel usando GCP. Eu proponho o seguinte:

##### ðŸ•¹ï¸ Requisitos da Arquitetura

Modelos **Batch** ðŸ“¦:

- Processamento periÃ³dico de mÃ©dio volumes de dados.

Exemplos: previsÃµes diÃ¡rias, geraÃ§Ã£o de relatÃ³rios, treinamento de modelos.

Modelos **Fast** âš¡:

Respostas em tempo real ou near real-time.

##### ðŸŽ¯ Arquitetura Proposta

1. Coleta de Dados ðŸ“¶

- Cloud Pub/Sub: Para ingestÃ£o de dados em tempo real (fast).
- Cloud Storage: Para armazenamento de dados brutos em lote (batch).
  
Exemplos: APIs para previsÃµes sob demanda, detecÃ§Ã£o de anomalias em tempo real.

2. Processamento de Dados ðŸ§® 

- Dataflow: Para processamento de dados em batch e streaming.
- BigQuery: Para armazenar dados processados e estruturados.

3. Treinamento de Modelos ðŸ¤–

- Vertex AI Training: Para treinar modelos de forma gerenciada.
- Cloud Storage: Para armazenar modelos treinados e backups.

3. Armazenamento / Controle de Modelos ðŸ—‚ï¸

- Vertex AI Model Registry: Para versionamento e gerenciamento de modelos.
- Cloud Storage: Para armazenar arquivos de modelos (heights, pickle, etc.).

5. Deploy ðŸš€
   
- Vertex AI Endpoints: Para servir modelos em tempo real (fast).
- Cloud Functions ou Cloud Run: Para execuÃ§Ã£o de modelos batch sob demanda ou em horÃ¡rios agendados.

Para caso de modelo batch disponibilizaÃ§Ã£o das inferÃªncias em uma tabela no Big Query cliente.

6. Monitoramento e Logging ðŸ”

- Cloud Logging: Coleta e armazenamento de logs em grande escala.
- Vertex AI Model Monitoring: Escalabilidade automÃ¡tica para monitorar a qualidade dos modelos em produÃ§Ã£o (drift e mÃ©tricas).

7. Diagrama ðŸ“Š

Fluxo bÃ¡sico para modelos **Fast** e **Batch**

```mermaid
flowchart TD
    A[Coleta de Dados] --> B[Cloud Pub/Sub]
    A --> C[Cloud Storage]
    B --> D[Dataflow Streaming]
    C --> E[Dataflow Batch]
    D --> F[BigQuery]
    E --> G[Vertex AI Training]
    F --> H[Vertex AI Endpoints]
    G --> I[Cloud Storage Modelos]
```

### 2. ðŸ•¸ï¸ CI/CD para Machine Learning
    H --> J[Cloud Logging & Monitoring]
    I --> K[Cloud Scheduler + Cloud Run]


